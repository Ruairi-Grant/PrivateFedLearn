{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\git_repos\\Thesis\\flowerEnv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\git_repos\\Thesis\\flowerEnv\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py:74: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\git_repos\\Thesis\\flowerEnv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\git_repos\\Thesis\\flowerEnv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# General Utility imports\n",
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Tensorflow model import\n",
    "import tensorflow as tf\n",
    "from keras import layers as tfkl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "# Tensorflow Privacy\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasSGDOptimizer\n",
    "import dp_accounting\n",
    "\n",
    "# Matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom modules\n",
    "from MySqueezeNet import SqueezeNet\n",
    "import common\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIGH PRIORITY\n",
    "# TODO: Include the test data in the test set, this could be either the test set or the val and test set - maybe put the download data script in a seperate script\n",
    "# TODO: Figure out a way to get a confusion matrix and classification report\n",
    "# TODO: Experiment with bringing the rescaling back, try other scaling and standardization techniques\n",
    "# TODO: look at ways of loading the data without image_dataset_from_directory\n",
    "# LOW PRIORITY\n",
    "# TODO: Look into using a cache for loaded images\n",
    "# TODO: Investigate message \"filling up shuffle buffer\"\n",
    "# TODO: experiment with techniques to make white stand out more in images\n",
    "# TODO: experiment with other hyperparamaters\n",
    "# TODO: Experiment with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defing Hyperparamaters\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 50\n",
    "SEED = 42\n",
    "IMAGE_SIZE = [265, 265]\n",
    "DATA_DIR = Path(os.path.join(\"Datasets\", \"aptos2019-blindness-detection\", \"train\"))\n",
    "RESULTS_DIR = os.path.join(\"Results\", \"Centralized_DR\")\n",
    "\n",
    "\n",
    "NOISE_MULTIPLIER = 0.3\n",
    "DIFFERENTIAL_PRIVACY = True\n",
    "L2_NORM_CLIP = 1.5\n",
    "LEARNING_RATE = 0.02\n",
    "MICROBATCHES = 1\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 2930\n",
      "Validation data size: 732\n"
     ]
    }
   ],
   "source": [
    "# create train and test datasets\n",
    "image_count = len(list(DATA_DIR.glob(\"*/*.png\")))\n",
    "\n",
    "# Create a dataset from the filtered file paths\n",
    "list_ds = tf.data.Dataset.list_files(str(DATA_DIR / \"*/*\"), shuffle=False)\n",
    "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)\n",
    "\n",
    "class_names = np.array(sorted([item.name for item in DATA_DIR.glob(\"*\")]))\n",
    "\n",
    "# split the dataset into training and validation sets\n",
    "val_size = int(image_count * 0.2)\n",
    "train_ds = list_ds.skip(val_size)\n",
    "val_ds = list_ds.take(val_size)\n",
    "\n",
    "print(f\"Training data size: {tf.data.experimental.cardinality(train_ds).numpy()}\")\n",
    "print(f\"Validation data size: {tf.data.experimental.cardinality(val_ds).numpy()}\")\n",
    "\n",
    "# map the image paths to the images and labels\n",
    "train_ds = train_ds.map(lambda x: common.process_path(x, class_names, IMAGE_SIZE))\n",
    "val_ds = val_ds.map(lambda x: common.process_path(x, class_names, IMAGE_SIZE))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(265, 265, 3), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = common.configure_for_performance(train_ds, BATCH_SIZE)\n",
    "val_ds = common.configure_for_performance(val_ds, BATCH_SIZE)\n",
    "\n",
    "print(\n",
    "    f\"Training class distribution: {common.get_class_count(len(class_names), train_ds )}\"\n",
    ")\n",
    "print(\n",
    "    f\"Validation class distribution: {common.get_class_count(len(class_names), val_ds )}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\git_repos\\Thesis\\flowerEnv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Post processing training class distribution: [1432  300  821  144  233]\n",
      "Post processing Validation class distribution: [373  70 178  49  62]\n"
     ]
    }
   ],
   "source": [
    "data_prep = tf.keras.Sequential(\n",
    "    [\n",
    "        tfkl.Rescaling(1./255),\n",
    "        tfkl.CenterCrop(224, 224)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([data_prep, tfkl.RandomFlip(\"horizontal\")])\n",
    "\n",
    "\n",
    "# prepare the datasets\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (data_prep(x), y))\n",
    "\n",
    "print(\n",
    "    f\"Post processing training class distribution: {common.get_class_count(len(class_names), train_ds )}\"\n",
    ")\n",
    "print(\n",
    "    f\"Post processing Validation class distribution: {common.get_class_count(len(class_names), val_ds )}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\git_repos\\Thesis\\flowerEnv\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\git_repos\\Thesis\\flowerEnv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)              (None, 111, 111, 64)         1792      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " relu_conv1 (Activation)     (None, 111, 111, 64)         0         ['conv1[0][0]']               \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)        (None, 55, 55, 64)           0         ['relu_conv1[0][0]']          \n",
      "                                                                                                  \n",
      " fire2/squeeze1x1 (Conv2D)   (None, 55, 55, 16)           1040      ['pool1[0][0]']               \n",
      "                                                                                                  \n",
      " fire2/relu_squeeze1x1 (Act  (None, 55, 55, 16)           0         ['fire2/squeeze1x1[0][0]']    \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " fire2/expand1x1 (Conv2D)    (None, 55, 55, 64)           1088      ['fire2/relu_squeeze1x1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " fire2/expand3x3 (Conv2D)    (None, 55, 55, 64)           9280      ['fire2/relu_squeeze1x1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " fire2/relu_expand1x1 (Acti  (None, 55, 55, 64)           0         ['fire2/expand1x1[0][0]']     \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " fire2/relu_expand3x3 (Acti  (None, 55, 55, 64)           0         ['fire2/expand3x3[0][0]']     \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " fire2/concat (Concatenate)  (None, 55, 55, 128)          0         ['fire2/relu_expand1x1[0][0]',\n",
      "                                                                     'fire2/relu_expand3x3[0][0]']\n",
      "                                                                                                  \n",
      " fire3/squeeze1x1 (Conv2D)   (None, 55, 55, 16)           2064      ['fire2/concat[0][0]']        \n",
      "                                                                                                  \n",
      " fire3/relu_squeeze1x1 (Act  (None, 55, 55, 16)           0         ['fire3/squeeze1x1[0][0]']    \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " fire3/expand1x1 (Conv2D)    (None, 55, 55, 64)           1088      ['fire3/relu_squeeze1x1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " fire3/expand3x3 (Conv2D)    (None, 55, 55, 64)           9280      ['fire3/relu_squeeze1x1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " fire3/relu_expand1x1 (Acti  (None, 55, 55, 64)           0         ['fire3/expand1x1[0][0]']     \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " fire3/relu_expand3x3 (Acti  (None, 55, 55, 64)           0         ['fire3/expand3x3[0][0]']     \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " fire3/concat (Concatenate)  (None, 55, 55, 128)          0         ['fire3/relu_expand1x1[0][0]',\n",
      "                                                                     'fire3/relu_expand3x3[0][0]']\n",
      "                                                                                                  \n",
      " pool3 (MaxPooling2D)        (None, 27, 27, 128)          0         ['fire3/concat[0][0]']        \n",
      "                                                                                                  \n",
      " fire4/squeeze1x1 (Conv2D)   (None, 27, 27, 32)           4128      ['pool3[0][0]']               \n",
      "                                                                                                  \n",
      " fire4/relu_squeeze1x1 (Act  (None, 27, 27, 32)           0         ['fire4/squeeze1x1[0][0]']    \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " fire4/expand1x1 (Conv2D)    (None, 27, 27, 128)          4224      ['fire4/relu_squeeze1x1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " fire4/expand3x3 (Conv2D)    (None, 27, 27, 128)          36992     ['fire4/relu_squeeze1x1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " fire4/relu_expand1x1 (Acti  (None, 27, 27, 128)          0         ['fire4/expand1x1[0][0]']     \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " fire4/relu_expand3x3 (Acti  (None, 27, 27, 128)          0         ['fire4/expand3x3[0][0]']     \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " fire4/concat (Concatenate)  (None, 27, 27, 256)          0         ['fire4/relu_expand1x1[0][0]',\n",
      "                                                                     'fire4/relu_expand3x3[0][0]']\n",
      "                                                                                                  \n",
      " fire5/squeeze1x1 (Conv2D)   (None, 27, 27, 32)           8224      ['fire4/concat[0][0]']        \n",
      "                                                                                                  \n",
      " fire5/relu_squeeze1x1 (Act  (None, 27, 27, 32)           0         ['fire5/squeeze1x1[0][0]']    \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " fire5/expand1x1 (Conv2D)    (None, 27, 27, 128)          4224      ['fire5/relu_squeeze1x1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " fire5/expand3x3 (Conv2D)    (None, 27, 27, 128)          36992     ['fire5/relu_squeeze1x1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " fire5/relu_expand1x1 (Acti  (None, 27, 27, 128)          0         ['fire5/expand1x1[0][0]']     \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " fire5/relu_expand3x3 (Acti  (None, 27, 27, 128)          0         ['fire5/expand3x3[0][0]']     \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " fire5/concat (Concatenate)  (None, 27, 27, 256)          0         ['fire5/relu_expand1x1[0][0]',\n",
      "                                                                     'fire5/relu_expand3x3[0][0]']\n",
      "                                                                                                  \n",
      " pool5 (MaxPooling2D)        (None, 13, 13, 256)          0         ['fire5/concat[0][0]']        \n",
      "                                                                                                  \n",
      " fire6/squeeze1x1 (Conv2D)   (None, 13, 13, 48)           12336     ['pool5[0][0]']               \n",
      "                                                                                                  \n",
      " fire6/relu_squeeze1x1 (Act  (None, 13, 13, 48)           0         ['fire6/squeeze1x1[0][0]']    \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " fire6/expand1x1 (Conv2D)    (None, 13, 13, 192)          9408      ['fire6/relu_squeeze1x1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " fire6/expand3x3 (Conv2D)    (None, 13, 13, 192)          83136     ['fire6/relu_squeeze1x1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " fire6/relu_expand1x1 (Acti  (None, 13, 13, 192)          0         ['fire6/expand1x1[0][0]']     \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " fire6/relu_expand3x3 (Acti  (None, 13, 13, 192)          0         ['fire6/expand3x3[0][0]']     \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " fire6/concat (Concatenate)  (None, 13, 13, 384)          0         ['fire6/relu_expand1x1[0][0]',\n",
      "                                                                     'fire6/relu_expand3x3[0][0]']\n",
      "                                                                                                  \n",
      " fire7/squeeze1x1 (Conv2D)   (None, 13, 13, 48)           18480     ['fire6/concat[0][0]']        \n",
      "                                                                                                  \n",
      " fire7/relu_squeeze1x1 (Act  (None, 13, 13, 48)           0         ['fire7/squeeze1x1[0][0]']    \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " fire7/expand1x1 (Conv2D)    (None, 13, 13, 192)          9408      ['fire7/relu_squeeze1x1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " fire7/expand3x3 (Conv2D)    (None, 13, 13, 192)          83136     ['fire7/relu_squeeze1x1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " fire7/relu_expand1x1 (Acti  (None, 13, 13, 192)          0         ['fire7/expand1x1[0][0]']     \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " fire7/relu_expand3x3 (Acti  (None, 13, 13, 192)          0         ['fire7/expand3x3[0][0]']     \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " fire7/concat (Concatenate)  (None, 13, 13, 384)          0         ['fire7/relu_expand1x1[0][0]',\n",
      "                                                                     'fire7/relu_expand3x3[0][0]']\n",
      "                                                                                                  \n",
      " fire8/squeeze1x1 (Conv2D)   (None, 13, 13, 64)           24640     ['fire7/concat[0][0]']        \n",
      "                                                                                                  \n",
      " fire8/relu_squeeze1x1 (Act  (None, 13, 13, 64)           0         ['fire8/squeeze1x1[0][0]']    \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " fire8/expand1x1 (Conv2D)    (None, 13, 13, 256)          16640     ['fire8/relu_squeeze1x1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " fire8/expand3x3 (Conv2D)    (None, 13, 13, 256)          147712    ['fire8/relu_squeeze1x1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " fire8/relu_expand1x1 (Acti  (None, 13, 13, 256)          0         ['fire8/expand1x1[0][0]']     \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " fire8/relu_expand3x3 (Acti  (None, 13, 13, 256)          0         ['fire8/expand3x3[0][0]']     \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " fire8/concat (Concatenate)  (None, 13, 13, 512)          0         ['fire8/relu_expand1x1[0][0]',\n",
      "                                                                     'fire8/relu_expand3x3[0][0]']\n",
      "                                                                                                  \n",
      " fire9/squeeze1x1 (Conv2D)   (None, 13, 13, 64)           32832     ['fire8/concat[0][0]']        \n",
      "                                                                                                  \n",
      " fire9/relu_squeeze1x1 (Act  (None, 13, 13, 64)           0         ['fire9/squeeze1x1[0][0]']    \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " fire9/expand1x1 (Conv2D)    (None, 13, 13, 256)          16640     ['fire9/relu_squeeze1x1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " fire9/expand3x3 (Conv2D)    (None, 13, 13, 256)          147712    ['fire9/relu_squeeze1x1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " fire9/relu_expand1x1 (Acti  (None, 13, 13, 256)          0         ['fire9/expand1x1[0][0]']     \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " fire9/relu_expand3x3 (Acti  (None, 13, 13, 256)          0         ['fire9/expand3x3[0][0]']     \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " fire9/concat (Concatenate)  (None, 13, 13, 512)          0         ['fire9/relu_expand1x1[0][0]',\n",
      "                                                                     'fire9/relu_expand3x3[0][0]']\n",
      "                                                                                                  \n",
      " drop9 (Dropout)             (None, 13, 13, 512)          0         ['fire9/concat[0][0]']        \n",
      "                                                                                                  \n",
      " conv10 (Conv2D)             (None, 13, 13, 5)            2565      ['drop9[0][0]']               \n",
      "                                                                                                  \n",
      " relu_conv10 (Activation)    (None, 13, 13, 5)            0         ['conv10[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 5)                    0         ['relu_conv10[0][0]']         \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " loss (Activation)           (None, 5)                    0         ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 725061 (2.77 MB)\n",
      "Trainable params: 725061 (2.77 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = SqueezeNet(include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "if DIFFERENTIAL_PRIVACY:\n",
    "    optimizer = DPKerasSGDOptimizer(\n",
    "        l2_norm_clip=L2_NORM_CLIP,\n",
    "        noise_multiplier=NOISE_MULTIPLIER,\n",
    "        num_microbatches=MICROBATCHES,\n",
    "        momentum=MOMENTUM,\n",
    "    )\n",
    "    # Compute vector of per-example loss rather than its mean over a minibatch.\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        reduction=tf.losses.Reduction.NONE\n",
    "    )\n",
    "else:\n",
    "    optimizer = tf.keras.optimizers.experimental.SGD(\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        momentum=MOMENTUM\n",
    "    )\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\git_repos\\Thesis\\flowerEnv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\git_repos\\Thesis\\flowerEnv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "59/59 [==============================] - ETA: 0s - loss: 1.3054 - accuracy: 0.4945\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50956, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git_repos\\Thesis\\flowerEnv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 71s 1s/step - loss: 1.3054 - accuracy: 0.4945 - val_loss: 1.0038 - val_accuracy: 0.5096\n",
      "Epoch 2/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.9038 - accuracy: 0.6980\n",
      "Epoch 2: val_accuracy improved from 0.50956 to 0.63115, saving model to best_model.h5\n",
      "59/59 [==============================] - 60s 1s/step - loss: 0.9038 - accuracy: 0.6980 - val_loss: 0.9817 - val_accuracy: 0.6311\n",
      "Epoch 3/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.8294 - accuracy: 0.7198\n",
      "Epoch 3: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 61s 1s/step - loss: 0.8294 - accuracy: 0.7198 - val_loss: 0.9701 - val_accuracy: 0.5683\n",
      "Epoch 4/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.7933 - accuracy: 0.7273\n",
      "Epoch 4: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 60s 1s/step - loss: 0.7933 - accuracy: 0.7273 - val_loss: 1.0230 - val_accuracy: 0.5683\n",
      "Epoch 5/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.7619 - accuracy: 0.7379\n",
      "Epoch 5: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 57s 967ms/step - loss: 0.7619 - accuracy: 0.7379 - val_loss: 0.9116 - val_accuracy: 0.5984\n",
      "Epoch 6/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.7098 - accuracy: 0.7488\n",
      "Epoch 6: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 57s 975ms/step - loss: 0.7098 - accuracy: 0.7488 - val_loss: 0.9996 - val_accuracy: 0.5519\n",
      "Epoch 7/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.6850 - accuracy: 0.7529\n",
      "Epoch 7: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 59s 999ms/step - loss: 0.6850 - accuracy: 0.7529 - val_loss: 1.0012 - val_accuracy: 0.5697\n",
      "Epoch 8/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.7339 - accuracy: 0.7406\n",
      "Epoch 8: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 59s 997ms/step - loss: 0.7339 - accuracy: 0.7406 - val_loss: 0.9195 - val_accuracy: 0.5738\n",
      "Epoch 9/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.7138 - accuracy: 0.7522\n",
      "Epoch 9: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 58s 989ms/step - loss: 0.7138 - accuracy: 0.7522 - val_loss: 0.9161 - val_accuracy: 0.5710\n",
      "Epoch 10/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.6645 - accuracy: 0.7543\n",
      "Epoch 10: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 57s 961ms/step - loss: 0.6645 - accuracy: 0.7543 - val_loss: 0.9295 - val_accuracy: 0.5533\n",
      "Epoch 11/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.6385 - accuracy: 0.7655\n",
      "Epoch 11: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 57s 967ms/step - loss: 0.6385 - accuracy: 0.7655 - val_loss: 0.8632 - val_accuracy: 0.5806\n",
      "Epoch 12/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.6419 - accuracy: 0.7604\n",
      "Epoch 12: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 58s 977ms/step - loss: 0.6419 - accuracy: 0.7604 - val_loss: 0.8902 - val_accuracy: 0.5656\n",
      "Epoch 13/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.6211 - accuracy: 0.7717\n",
      "Epoch 13: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 58s 985ms/step - loss: 0.6211 - accuracy: 0.7717 - val_loss: 0.8895 - val_accuracy: 0.5820\n",
      "Epoch 14/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.6183 - accuracy: 0.7669\n",
      "Epoch 14: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 60s 1s/step - loss: 0.6183 - accuracy: 0.7669 - val_loss: 0.8925 - val_accuracy: 0.5642\n",
      "Epoch 15/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.6299 - accuracy: 0.7679\n",
      "Epoch 15: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 57s 958ms/step - loss: 0.6299 - accuracy: 0.7679 - val_loss: 0.9080 - val_accuracy: 0.5765\n",
      "Epoch 16/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.6151 - accuracy: 0.7758\n",
      "Epoch 16: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 57s 966ms/step - loss: 0.6151 - accuracy: 0.7758 - val_loss: 0.9405 - val_accuracy: 0.5710\n",
      "Epoch 17/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.6027 - accuracy: 0.7741\n",
      "Epoch 17: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 57s 970ms/step - loss: 0.6027 - accuracy: 0.7741 - val_loss: 0.8690 - val_accuracy: 0.6093\n",
      "Epoch 18/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.5951 - accuracy: 0.7785\n",
      "Epoch 18: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 59s 998ms/step - loss: 0.5951 - accuracy: 0.7785 - val_loss: 0.8415 - val_accuracy: 0.6134\n",
      "Epoch 19/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.5754 - accuracy: 0.7782\n",
      "Epoch 19: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 58s 978ms/step - loss: 0.5754 - accuracy: 0.7782 - val_loss: 0.9063 - val_accuracy: 0.5710\n",
      "Epoch 20/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.5857 - accuracy: 0.7700\n",
      "Epoch 20: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 58s 984ms/step - loss: 0.5857 - accuracy: 0.7700 - val_loss: 0.8574 - val_accuracy: 0.6011\n",
      "Epoch 21/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.5776 - accuracy: 0.7843\n",
      "Epoch 21: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 57s 962ms/step - loss: 0.5776 - accuracy: 0.7843 - val_loss: 1.0089 - val_accuracy: 0.5656\n",
      "Epoch 22/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.5624 - accuracy: 0.7829\n",
      "Epoch 22: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 57s 960ms/step - loss: 0.5624 - accuracy: 0.7829 - val_loss: 0.8188 - val_accuracy: 0.6243\n",
      "Epoch 23/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.5795 - accuracy: 0.7836\n",
      "Epoch 23: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 56s 956ms/step - loss: 0.5795 - accuracy: 0.7836 - val_loss: 0.8423 - val_accuracy: 0.6161\n",
      "Epoch 24/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.5423 - accuracy: 0.7915\n",
      "Epoch 24: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 57s 965ms/step - loss: 0.5423 - accuracy: 0.7915 - val_loss: 0.8093 - val_accuracy: 0.6189\n",
      "Epoch 25/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.5431 - accuracy: 0.7911\n",
      "Epoch 25: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 57s 971ms/step - loss: 0.5431 - accuracy: 0.7911 - val_loss: 0.8163 - val_accuracy: 0.6311\n",
      "Epoch 26/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.5582 - accuracy: 0.7829\n",
      "Epoch 26: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 57s 965ms/step - loss: 0.5582 - accuracy: 0.7829 - val_loss: 0.8102 - val_accuracy: 0.6270\n",
      "Epoch 27/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.5167 - accuracy: 0.7990\n",
      "Epoch 27: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 56s 954ms/step - loss: 0.5167 - accuracy: 0.7990 - val_loss: 0.8606 - val_accuracy: 0.6161\n",
      "Epoch 28/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.5183 - accuracy: 0.7945\n",
      "Epoch 28: val_accuracy did not improve from 0.63115\n",
      "59/59 [==============================] - 57s 960ms/step - loss: 0.5183 - accuracy: 0.7945 - val_loss: 0.9953 - val_accuracy: 0.5929\n",
      "Epoch 29/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.5382 - accuracy: 0.7908\n",
      "Epoch 29: val_accuracy improved from 0.63115 to 0.64481, saving model to best_model.h5\n",
      "59/59 [==============================] - 58s 979ms/step - loss: 0.5382 - accuracy: 0.7908 - val_loss: 0.8113 - val_accuracy: 0.6448\n",
      "Epoch 30/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.4979 - accuracy: 0.8082\n",
      "Epoch 30: val_accuracy improved from 0.64481 to 0.65027, saving model to best_model.h5\n",
      "59/59 [==============================] - 58s 981ms/step - loss: 0.4979 - accuracy: 0.8082 - val_loss: 0.8097 - val_accuracy: 0.6503\n",
      "Epoch 31/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.5040 - accuracy: 0.8041\n",
      "Epoch 31: val_accuracy improved from 0.65027 to 0.72268, saving model to best_model.h5\n",
      "59/59 [==============================] - 57s 975ms/step - loss: 0.5040 - accuracy: 0.8041 - val_loss: 0.7960 - val_accuracy: 0.7227\n",
      "Epoch 32/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.5248 - accuracy: 0.7925\n",
      "Epoch 32: val_accuracy improved from 0.72268 to 0.73634, saving model to best_model.h5\n",
      "59/59 [==============================] - 57s 967ms/step - loss: 0.5248 - accuracy: 0.7925 - val_loss: 0.6356 - val_accuracy: 0.7363\n",
      "Epoch 33/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.5447 - accuracy: 0.7911\n",
      "Epoch 33: val_accuracy did not improve from 0.73634\n",
      "59/59 [==============================] - 58s 988ms/step - loss: 0.5447 - accuracy: 0.7911 - val_loss: 0.6672 - val_accuracy: 0.7350\n",
      "Epoch 34/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.5087 - accuracy: 0.8000\n",
      "Epoch 34: val_accuracy improved from 0.73634 to 0.75956, saving model to best_model.h5\n",
      "59/59 [==============================] - 58s 984ms/step - loss: 0.5087 - accuracy: 0.8000 - val_loss: 0.5786 - val_accuracy: 0.7596\n",
      "Epoch 35/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.4968 - accuracy: 0.8034\n",
      "Epoch 35: val_accuracy did not improve from 0.75956\n",
      "59/59 [==============================] - 58s 988ms/step - loss: 0.4968 - accuracy: 0.8034 - val_loss: 0.6790 - val_accuracy: 0.7227\n",
      "Epoch 36/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.4850 - accuracy: 0.8123\n",
      "Epoch 36: val_accuracy improved from 0.75956 to 0.76230, saving model to best_model.h5\n",
      "59/59 [==============================] - 58s 975ms/step - loss: 0.4850 - accuracy: 0.8123 - val_loss: 0.6093 - val_accuracy: 0.7623\n",
      "Epoch 37/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.4622 - accuracy: 0.8174\n",
      "Epoch 37: val_accuracy did not improve from 0.76230\n",
      "59/59 [==============================] - 57s 967ms/step - loss: 0.4622 - accuracy: 0.8174 - val_loss: 0.6919 - val_accuracy: 0.7350\n",
      "Epoch 38/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.4684 - accuracy: 0.8198\n",
      "Epoch 38: val_accuracy did not improve from 0.76230\n",
      "59/59 [==============================] - 56s 957ms/step - loss: 0.4684 - accuracy: 0.8198 - val_loss: 0.6295 - val_accuracy: 0.7473\n",
      "Epoch 39/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.4677 - accuracy: 0.8225\n",
      "Epoch 39: val_accuracy did not improve from 0.76230\n",
      "59/59 [==============================] - 57s 965ms/step - loss: 0.4677 - accuracy: 0.8225 - val_loss: 0.6756 - val_accuracy: 0.7295\n",
      "Epoch 40/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.4579 - accuracy: 0.8229\n",
      "Epoch 40: val_accuracy did not improve from 0.76230\n",
      "59/59 [==============================] - 57s 973ms/step - loss: 0.4579 - accuracy: 0.8229 - val_loss: 0.5863 - val_accuracy: 0.7541\n",
      "Epoch 41/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.4308 - accuracy: 0.8386\n",
      "Epoch 41: val_accuracy improved from 0.76230 to 0.77596, saving model to best_model.h5\n",
      "59/59 [==============================] - 58s 983ms/step - loss: 0.4308 - accuracy: 0.8386 - val_loss: 0.5167 - val_accuracy: 0.7760\n",
      "Epoch 42/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.5119 - accuracy: 0.8102\n",
      "Epoch 42: val_accuracy improved from 0.77596 to 0.81557, saving model to best_model.h5\n",
      "59/59 [==============================] - 57s 964ms/step - loss: 0.5119 - accuracy: 0.8102 - val_loss: 0.5111 - val_accuracy: 0.8156\n",
      "Epoch 43/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.4654 - accuracy: 0.8195\n",
      "Epoch 43: val_accuracy did not improve from 0.81557\n",
      "59/59 [==============================] - 57s 966ms/step - loss: 0.4654 - accuracy: 0.8195 - val_loss: 0.7285 - val_accuracy: 0.7486\n",
      "Epoch 44/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.4564 - accuracy: 0.8256\n",
      "Epoch 44: val_accuracy improved from 0.81557 to 0.81694, saving model to best_model.h5\n",
      "59/59 [==============================] - 59s 996ms/step - loss: 0.4564 - accuracy: 0.8256 - val_loss: 0.4915 - val_accuracy: 0.8169\n",
      "Epoch 45/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.4398 - accuracy: 0.8246\n",
      "Epoch 45: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 57s 969ms/step - loss: 0.4398 - accuracy: 0.8246 - val_loss: 0.5439 - val_accuracy: 0.7951\n",
      "Epoch 46/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.4371 - accuracy: 0.8276\n",
      "Epoch 46: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 58s 977ms/step - loss: 0.4371 - accuracy: 0.8276 - val_loss: 0.5144 - val_accuracy: 0.7992\n",
      "Epoch 47/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.4456 - accuracy: 0.8328\n",
      "Epoch 47: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 56s 957ms/step - loss: 0.4456 - accuracy: 0.8328 - val_loss: 0.5313 - val_accuracy: 0.8060\n",
      "Epoch 48/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.4001 - accuracy: 0.8532\n",
      "Epoch 48: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 57s 974ms/step - loss: 0.4001 - accuracy: 0.8532 - val_loss: 0.5806 - val_accuracy: 0.7951\n",
      "Epoch 49/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.3898 - accuracy: 0.8532\n",
      "Epoch 49: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 57s 960ms/step - loss: 0.3898 - accuracy: 0.8532 - val_loss: 0.4902 - val_accuracy: 0.8156\n",
      "Epoch 50/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.3854 - accuracy: 0.8529\n",
      "Epoch 50: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 58s 980ms/step - loss: 0.3854 - accuracy: 0.8529 - val_loss: 0.5292 - val_accuracy: 0.8005\n",
      "Epoch 51/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.3882 - accuracy: 0.8509\n",
      "Epoch 51: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 58s 976ms/step - loss: 0.3882 - accuracy: 0.8509 - val_loss: 0.5635 - val_accuracy: 0.8074\n",
      "Epoch 52/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.3762 - accuracy: 0.8621\n",
      "Epoch 52: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 57s 964ms/step - loss: 0.3762 - accuracy: 0.8621 - val_loss: 0.5912 - val_accuracy: 0.8060\n",
      "Epoch 53/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.3945 - accuracy: 0.8532\n",
      "Epoch 53: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 57s 961ms/step - loss: 0.3945 - accuracy: 0.8532 - val_loss: 0.5029 - val_accuracy: 0.8169\n",
      "Epoch 54/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.3491 - accuracy: 0.8652\n",
      "Epoch 54: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 57s 971ms/step - loss: 0.3491 - accuracy: 0.8652 - val_loss: 0.6100 - val_accuracy: 0.7964\n",
      "Epoch 55/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.3661 - accuracy: 0.8621\n",
      "Epoch 55: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 57s 962ms/step - loss: 0.3661 - accuracy: 0.8621 - val_loss: 0.5203 - val_accuracy: 0.8019\n",
      "Epoch 56/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.3447 - accuracy: 0.8676\n",
      "Epoch 56: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 59s 1s/step - loss: 0.3447 - accuracy: 0.8676 - val_loss: 0.4971 - val_accuracy: 0.8169\n",
      "Epoch 57/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.3401 - accuracy: 0.8734\n",
      "Epoch 57: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 56s 956ms/step - loss: 0.3401 - accuracy: 0.8734 - val_loss: 0.5353 - val_accuracy: 0.8169\n",
      "Epoch 58/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.3319 - accuracy: 0.8775\n",
      "Epoch 58: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 57s 965ms/step - loss: 0.3319 - accuracy: 0.8775 - val_loss: 0.5949 - val_accuracy: 0.7746\n",
      "Epoch 59/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.3180 - accuracy: 0.8717\n",
      "Epoch 59: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 62s 1s/step - loss: 0.3180 - accuracy: 0.8717 - val_loss: 0.6791 - val_accuracy: 0.8087\n",
      "Epoch 60/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.3536 - accuracy: 0.8720\n",
      "Epoch 60: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 60s 1s/step - loss: 0.3536 - accuracy: 0.8720 - val_loss: 0.5387 - val_accuracy: 0.7910\n",
      "Epoch 61/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.8730\n",
      "Epoch 61: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 58s 984ms/step - loss: 0.3143 - accuracy: 0.8730 - val_loss: 0.5389 - val_accuracy: 0.8060\n",
      "Epoch 62/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.3209 - accuracy: 0.8826\n",
      "Epoch 62: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 58s 983ms/step - loss: 0.3209 - accuracy: 0.8826 - val_loss: 0.6454 - val_accuracy: 0.7801\n",
      "Epoch 63/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.3212 - accuracy: 0.8727\n",
      "Epoch 63: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 60s 1s/step - loss: 0.3212 - accuracy: 0.8727 - val_loss: 0.7501 - val_accuracy: 0.7609\n",
      "Epoch 64/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8560\n",
      "Epoch 64: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 64s 1s/step - loss: 0.3861 - accuracy: 0.8560 - val_loss: 0.6632 - val_accuracy: 0.7773\n",
      "Epoch 65/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.3374 - accuracy: 0.8720\n",
      "Epoch 65: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 62s 1s/step - loss: 0.3374 - accuracy: 0.8720 - val_loss: 0.5962 - val_accuracy: 0.8087\n",
      "Epoch 66/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.3094 - accuracy: 0.8771\n",
      "Epoch 66: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 62s 1s/step - loss: 0.3094 - accuracy: 0.8771 - val_loss: 0.7270 - val_accuracy: 0.7814\n",
      "Epoch 67/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.3165 - accuracy: 0.8768\n",
      "Epoch 67: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 58s 980ms/step - loss: 0.3165 - accuracy: 0.8768 - val_loss: 0.5588 - val_accuracy: 0.8046\n",
      "Epoch 68/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.2541 - accuracy: 0.9007\n",
      "Epoch 68: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 56s 951ms/step - loss: 0.2541 - accuracy: 0.9007 - val_loss: 0.6609 - val_accuracy: 0.7978\n",
      "Epoch 69/100\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.2804 - accuracy: 0.8949\n",
      "Epoch 69: val_accuracy did not improve from 0.81694\n",
      "59/59 [==============================] - 59s 999ms/step - loss: 0.2804 - accuracy: 0.8949 - val_loss: 0.6263 - val_accuracy: 0.7896\n",
      "Epoch 69: early stopping\n"
     ]
    }
   ],
   "source": [
    "# simple early stopping\n",
    "#early_stopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=20)\n",
    "\n",
    "#checkpoint = ModelCheckpoint(\n",
    "#    \"best_model.h5\", monitor=\"val_accuracy\", mode=\"max\", verbose=1, save_best_only=True\n",
    "#)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    #callbacks=[early_stopping, checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model = load_model(\"best_model.h5\")\n",
    "\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "epochs_range = range(len(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the privacy budget expended.\n",
    "def compute_epsilon(epochs, num_data, batch_size):\n",
    "    \"\"\"Computes epsilon value for given hyperparameters.\"\"\"\n",
    "    steps = epochs * math.ceil(num_data / batch_size)\n",
    "    if NOISE_MULTIPLIER == 0.0:\n",
    "        return float(\"inf\")\n",
    "    orders = [1 + x / 10.0 for x in range(1, 100)] + list(range(12, 64))\n",
    "    # TODO:does this assume that i used SGD\n",
    "    accountant = dp_accounting.rdp.RdpAccountant(orders)\n",
    "\n",
    "    sampling_probability = batch_size / num_data\n",
    "    event = dp_accounting.SelfComposedDpEvent(\n",
    "        dp_accounting.PoissonSampledDpEvent(\n",
    "            sampling_probability, dp_accounting.GaussianDpEvent(NOISE_MULTIPLIER)\n",
    "        ),\n",
    "        steps,\n",
    "    )\n",
    "\n",
    "    accountant.compose(event)\n",
    "\n",
    "    return accountant.get_epsilon(target_delta=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the results directory exists\n",
    "if not os.path.exists(RESULTS_DIR):\n",
    "    os.makedirs(RESULTS_DIR)\n",
    "\n",
    "# PLot the dataset and save it\n",
    "fig1, ax1 = plt.subplots(figsize=(7, 5))\n",
    "ax1.plot(epochs_range, acc, label=\"Training Accuracy\")\n",
    "ax1.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\n",
    "ax1.legend(loc=\"lower right\")\n",
    "\n",
    "fig1.savefig(os.path.join(RESULTS_DIR, \"TrainingValidationAccuracy\"))\n",
    "\n",
    "# PLot the dataset and save it\n",
    "fig2, ax2 = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "ax2.plot(epochs_range, loss, label=\"Training Loss\")\n",
    "ax2.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
    "ax2.legend(loc=\"lower right\")\n",
    "fig2.savefig(os.path.join(RESULTS_DIR, \"TrainingValidationLoss\"))\n",
    "\n",
    "# Load the best model\n",
    "#best_model = load_model(\n",
    "#    \"best_model.h5\"\n",
    "#)  # TODO: Error here saying unknown optimizer, see github issue https://github.com/keras-team/tf-keras/issues/297\n",
    "\n",
    "# Evaluate the model\n",
    "common.evaluate_model(model, train_ds, os.path.join(RESULTS_DIR, \"Train\"))\n",
    "common.evaluate_model(model, val_ds, os.path.join(RESULTS_DIR, \"Validation\"))\n",
    "\n",
    "# TODO: make this accurate for my case\n",
    "# Compute the privacy budget expended.\n",
    "if DIFFERENTIAL_PRIVACY:\n",
    "    # eps = compute_epsilon(EPOCHS * 60000 // BATCH_SIZE)\n",
    "    eps = compute_epsilon(\n",
    "        len(loss), tf.data.experimental.cardinality(train_ds).numpy(), BATCH_SIZE\n",
    "    )\n",
    "    print(f\"For delta=1e-5, the current epsilon is: {eps}\")\n",
    "else:\n",
    "    print(\"Trained with vanilla non-private SGD optimizer\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flowerEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
